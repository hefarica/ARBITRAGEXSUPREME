# ArbitrageX Supreme - Performance Testing CI/CD Pipeline
# Ingenio Pichichi S.A. - Pipeline automatizado de pruebas de rendimiento
# TODO FUNCIONAL - CI/CD real para testing automatizado

name: 'Performance Testing Pipeline'

on:
  # Ejecutar en cada push a main y develop
  push:
    branches: [ main, develop ]
    paths:
      - 'src/**'
      - 'performance/**'
      - '.github/workflows/performance-testing.yml'
  
  # Ejecutar en pull requests
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'src/**'
      - 'performance/**'
  
  # Ejecutar manualmente
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        default: 'staging'
        type: choice
        options:
        - development
        - staging
        - production
      
      test_type:
        description: 'Test type to run'
        required: true
        default: 'load'
        type: choice
        options:
        - smoke
        - load
        - stress
        - websocket
        - blockchain
        - all
      
      parallel_execution:
        description: 'Run tests in parallel'
        required: false
        default: false
        type: boolean
      
      duration_minutes:
        description: 'Test duration in minutes'
        required: false
        default: '5'
        type: string

  # Ejecutar autom√°ticamente cada d√≠a a las 2:00 AM UTC
  schedule:
    - cron: '0 2 * * *'

env:
  NODE_VERSION: '20'
  K6_VERSION: '0.47.0'
  RESULTS_RETENTION_DAYS: 30

jobs:
  setup-and-validate:
    name: 'Setup & Validation'
    runs-on: ubuntu-latest
    outputs:
      environment: ${{ steps.config.outputs.environment }}
      test_type: ${{ steps.config.outputs.test_type }}
      parallel: ${{ steps.config.outputs.parallel }}
      base_url: ${{ steps.config.outputs.base_url }}
      ws_url: ${{ steps.config.outputs.ws_url }}
    
    steps:
      - name: 'Checkout Code'
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: 'Configure Test Parameters'
        id: config
        run: |
          # Determinar par√°metros basados en el contexto
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "environment=${{ github.event.inputs.environment }}" >> $GITHUB_OUTPUT
            echo "test_type=${{ github.event.inputs.test_type }}" >> $GITHUB_OUTPUT
            echo "parallel=${{ github.event.inputs.parallel_execution }}" >> $GITHUB_OUTPUT
          elif [[ "${{ github.event_name }}" == "schedule" ]]; then
            echo "environment=staging" >> $GITHUB_OUTPUT
            echo "test_type=all" >> $GITHUB_OUTPUT
            echo "parallel=true" >> $GITHUB_OUTPUT
          elif [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "environment=staging" >> $GITHUB_OUTPUT
            echo "test_type=load" >> $GITHUB_OUTPUT
            echo "parallel=false" >> $GITHUB_OUTPUT
          else
            echo "environment=development" >> $GITHUB_OUTPUT
            echo "test_type=smoke" >> $GITHUB_OUTPUT
            echo "parallel=false" >> $GITHUB_OUTPUT
          fi
          
          # Configurar URLs basadas en el ambiente
          case "$environment" in
            "production")
              echo "base_url=https://arbitragex.pichichi.com" >> $GITHUB_OUTPUT
              echo "ws_url=wss://arbitragex.pichichi.com/ws" >> $GITHUB_OUTPUT
              ;;
            "staging")
              echo "base_url=https://staging-arbitragex.pichichi.com" >> $GITHUB_OUTPUT
              echo "ws_url=wss://staging-arbitragex.pichichi.com/ws" >> $GITHUB_OUTPUT
              ;;
            *)
              echo "base_url=http://localhost:3000" >> $GITHUB_OUTPUT
              echo "ws_url=ws://localhost:3001/ws" >> $GITHUB_OUTPUT
              ;;
          esac

      - name: 'Validate Configuration'
        run: |
          echo "üîç Validando configuraci√≥n de pruebas..."
          echo "  ‚Ä¢ Ambiente: ${{ steps.config.outputs.environment }}"
          echo "  ‚Ä¢ Tipo de prueba: ${{ steps.config.outputs.test_type }}"
          echo "  ‚Ä¢ Ejecuci√≥n paralela: ${{ steps.config.outputs.parallel }}"
          echo "  ‚Ä¢ URL base: ${{ steps.config.outputs.base_url }}"
          echo "  ‚Ä¢ WebSocket URL: ${{ steps.config.outputs.ws_url }}"
          
          # Validar que los archivos necesarios existan
          if [[ ! -f "performance/k6/config/test-config.js" ]]; then
            echo "‚ùå Archivo de configuraci√≥n no encontrado"
            exit 1
          fi
          
          if [[ ! -d "performance/k6/tests" ]]; then
            echo "‚ùå Directorio de pruebas no encontrado"
            exit 1
          fi
          
          echo "‚úÖ Configuraci√≥n validada correctamente"

  service-health-check:
    name: 'Service Health Check'
    runs-on: ubuntu-latest
    needs: setup-and-validate
    if: needs.setup-and-validate.outputs.environment != 'development'
    
    steps:
      - name: 'Check Service Availability'
        run: |
          echo "üîç Verificando disponibilidad del servicio..."
          
          BASE_URL="${{ needs.setup-and-validate.outputs.base_url }}"
          
          # Verificar health endpoint
          if curl -s --max-time 30 "$BASE_URL/health" | jq -e '.status == "healthy"' > /dev/null; then
            echo "‚úÖ Servicio disponible y saludable"
          else
            echo "‚ùå Servicio no disponible o no saludable"
            exit 1
          fi
          
          # Verificar endpoints cr√≠ticos
          endpoints=("/api/chains" "/api/tokens" "/api/prices")
          
          for endpoint in "${endpoints[@]}"; do
            echo "  Verificando $endpoint..."
            if curl -s --max-time 15 "$BASE_URL$endpoint" > /dev/null; then
              echo "  ‚úÖ $endpoint disponible"
            else
              echo "  ‚ùå $endpoint no disponible"
              exit 1
            fi
          done
          
          echo "üéØ Todos los servicios est√°n operacionales"

  install-dependencies:
    name: 'Install Dependencies'
    runs-on: ubuntu-latest
    needs: setup-and-validate
    
    steps:
      - name: 'Checkout Code'
        uses: actions/checkout@v4

      - name: 'Setup Node.js'
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 'Install k6'
        run: |
          echo "üì¶ Instalando k6 v${{ env.K6_VERSION }}..."
          
          # Instalar k6
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6
          
          # Verificar instalaci√≥n
          k6 version
          echo "‚úÖ k6 instalado correctamente"

      - name: 'Install Additional Tools'
        run: |
          # Instalar herramientas adicionales
          sudo apt-get install -y jq bc curl
          
          echo "‚úÖ Herramientas adicionales instaladas"

      - name: 'Cache Dependencies'
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            ~/.k6
          key: ${{ runner.os }}-performance-deps-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-performance-deps-

  smoke-tests:
    name: 'Smoke Tests'
    runs-on: ubuntu-latest
    needs: [setup-and-validate, install-dependencies, service-health-check]
    if: always() && needs.setup-and-validate.result == 'success' && needs.install-dependencies.result == 'success' && (needs.service-health-check.result == 'success' || needs.service-health-check.result == 'skipped')
    
    steps:
      - name: 'Checkout Code'
        uses: actions/checkout@v4

      - name: 'Restore Dependencies Cache'
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            ~/.k6
          key: ${{ runner.os }}-performance-deps-${{ hashFiles('**/package-lock.json') }}

      - name: 'Install k6'
        run: |
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/kerrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6 jq

      - name: 'Run Smoke Tests'
        env:
          ENVIRONMENT: ${{ needs.setup-and-validate.outputs.environment }}
          BASE_URL: ${{ needs.setup-and-validate.outputs.base_url }}
        run: |
          echo "üöÄ Ejecutando pruebas de humo..."
          
          # Crear directorio de resultados
          mkdir -p performance/results
          
          # Ejecutar pruebas de humo
          k6 run \
            --env ENVIRONMENT="$ENVIRONMENT" \
            --env SCENARIO="smoke" \
            --env TEST_RUN_ID="smoke_ci_$(date +%s)" \
            --out json=performance/results/smoke_results.json \
            --summary-export=performance/results/smoke_summary.json \
            performance/k6/tests/api-load-test.js
          
          echo "‚úÖ Pruebas de humo completadas"

      - name: 'Analyze Smoke Test Results'
        run: |
          echo "üìä Analizando resultados de pruebas de humo..."
          
          if [[ -f "performance/results/smoke_summary.json" ]]; then
            # Extraer m√©tricas clave
            error_rate=$(jq -r '.metrics.http_req_failed.rate // 0' performance/results/smoke_summary.json)
            avg_duration=$(jq -r '.metrics.http_req_duration.avg // 0' performance/results/smoke_summary.json)
            p95_duration=$(jq -r '.metrics.http_req_duration.p95 // 0' performance/results/smoke_summary.json)
            
            echo "  ‚Ä¢ Tasa de error: $(echo "$error_rate * 100" | bc -l | cut -d. -f1)%"
            echo "  ‚Ä¢ Duraci√≥n promedio: ${avg_duration}ms"
            echo "  ‚Ä¢ Duraci√≥n P95: ${p95_duration}ms"
            
            # Validar umbrales cr√≠ticos
            if (( $(echo "$error_rate > 0.05" | bc -l) )); then
              echo "‚ùå Tasa de error demasiado alta: $(echo "$error_rate * 100" | bc -l)%"
              exit 1
            fi
            
            if (( $(echo "$p95_duration > 5000" | bc -l) )); then
              echo "‚ùå Latencia P95 demasiado alta: ${p95_duration}ms"
              exit 1
            fi
            
            echo "‚úÖ Pruebas de humo pasaron todos los umbrales"
          else
            echo "‚ùå Archivo de resumen no encontrado"
            exit 1
          fi

      - name: 'Upload Smoke Test Results'
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: smoke-test-results
          path: performance/results/
          retention-days: ${{ env.RESULTS_RETENTION_DAYS }}

  load-tests:
    name: 'Load Tests'
    runs-on: ubuntu-latest
    needs: [setup-and-validate, install-dependencies, smoke-tests]
    if: always() && needs.smoke-tests.result == 'success' && (needs.setup-and-validate.outputs.test_type == 'load' || needs.setup-and-validate.outputs.test_type == 'all')
    
    steps:
      - name: 'Checkout Code'
        uses: actions/checkout@v4

      - name: 'Install k6'
        run: |
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6 jq

      - name: 'Run Load Tests'
        env:
          ENVIRONMENT: ${{ needs.setup-and-validate.outputs.environment }}
          BASE_URL: ${{ needs.setup-and-validate.outputs.base_url }}
        run: |
          echo "‚ö° Ejecutando pruebas de carga..."
          
          mkdir -p performance/results
          
          k6 run \
            --env ENVIRONMENT="$ENVIRONMENT" \
            --env SCENARIO="load" \
            --env TEST_RUN_ID="load_ci_$(date +%s)" \
            --out json=performance/results/load_results.json \
            --summary-export=performance/results/load_summary.json \
            performance/k6/tests/api-load-test.js
          
          echo "‚úÖ Pruebas de carga completadas"

      - name: 'Upload Load Test Results'
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: load-test-results
          path: performance/results/
          retention-days: ${{ env.RESULTS_RETENTION_DAYS }}

  websocket-tests:
    name: 'WebSocket Tests'
    runs-on: ubuntu-latest
    needs: [setup-and-validate, install-dependencies, smoke-tests]
    if: always() && needs.smoke-tests.result == 'success' && (needs.setup-and-validate.outputs.test_type == 'websocket' || needs.setup-and-validate.outputs.test_type == 'all')
    
    steps:
      - name: 'Checkout Code'
        uses: actions/checkout@v4

      - name: 'Install k6'
        run: |
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: 'Run WebSocket Tests'
        env:
          ENVIRONMENT: ${{ needs.setup-and-validate.outputs.environment }}
          WS_URL: ${{ needs.setup-and-validate.outputs.ws_url }}
        run: |
          echo "üîå Ejecutando pruebas de WebSocket..."
          
          mkdir -p performance/results
          
          k6 run \
            --env ENVIRONMENT="$ENVIRONMENT" \
            --env TEST_RUN_ID="websocket_ci_$(date +%s)" \
            --out json=performance/results/websocket_results.json \
            --summary-export=performance/results/websocket_summary.json \
            performance/k6/tests/websocket-test.js
          
          echo "‚úÖ Pruebas de WebSocket completadas"

      - name: 'Upload WebSocket Test Results'
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: websocket-test-results
          path: performance/results/
          retention-days: ${{ env.RESULTS_RETENTION_DAYS }}

  blockchain-tests:
    name: 'Blockchain Tests'
    runs-on: ubuntu-latest
    needs: [setup-and-validate, install-dependencies, smoke-tests]
    if: always() && needs.smoke-tests.result == 'success' && (needs.setup-and-validate.outputs.test_type == 'blockchain' || needs.setup-and-validate.outputs.test_type == 'all')
    
    steps:
      - name: 'Checkout Code'
        uses: actions/checkout@v4

      - name: 'Install k6'
        run: |
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: 'Run Blockchain Tests'
        env:
          ENVIRONMENT: ${{ needs.setup-and-validate.outputs.environment }}
        run: |
          echo "üîó Ejecutando pruebas de blockchain..."
          
          mkdir -p performance/results
          
          k6 run \
            --env ENVIRONMENT="$ENVIRONMENT" \
            --env TEST_RUN_ID="blockchain_ci_$(date +%s)" \
            --out json=performance/results/blockchain_results.json \
            --summary-export=performance/results/blockchain_summary.json \
            performance/k6/tests/blockchain-stress-test.js
          
          echo "‚úÖ Pruebas de blockchain completadas"

      - name: 'Upload Blockchain Test Results'
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: blockchain-test-results
          path: performance/results/
          retention-days: ${{ env.RESULTS_RETENTION_DAYS }}

  generate-report:
    name: 'Generate Performance Report'
    runs-on: ubuntu-latest
    needs: [setup-and-validate, smoke-tests, load-tests, websocket-tests, blockchain-tests]
    if: always() && needs.smoke-tests.result != 'skipped'
    
    steps:
      - name: 'Checkout Code'
        uses: actions/checkout@v4

      - name: 'Download All Test Results'
        uses: actions/download-artifact@v4
        with:
          path: performance/results/

      - name: 'Generate Consolidated Report'
        run: |
          echo "üìä Generando reporte consolidado..."
          
          # Crear estructura de directorios
          mkdir -p performance/reports
          
          # Script para generar reporte HTML
          cat > performance/reports/generate_report.py << 'EOF'
          #!/usr/bin/env python3
          import json
          import os
          import glob
          from datetime import datetime
          import sys
          
          def load_test_results():
              results = {}
              
              # Buscar todos los archivos de resumen
              summary_files = glob.glob("performance/results/**/*summary.json", recursive=True)
              
              for file in summary_files:
                  try:
                      with open(file, 'r') as f:
                          data = json.load(f)
                      
                      # Determinar tipo de prueba por el nombre del archivo
                      if 'smoke' in file:
                          results['smoke'] = data
                      elif 'load' in file:
                          results['load'] = data
                      elif 'websocket' in file:
                          results['websocket'] = data
                      elif 'blockchain' in file:
                          results['blockchain'] = data
                  except Exception as e:
                      print(f"Error loading {file}: {e}")
              
              return results
          
          def generate_html_report(results):
              html = f'''
              <!DOCTYPE html>
              <html lang="es">
              <head>
                  <meta charset="UTF-8">
                  <meta name="viewport" content="width=device-width, initial-scale=1.0">
                  <title>ArbitrageX Supreme - Performance Report</title>
                  <style>
                      body {{ font-family: Arial, sans-serif; margin: 0; background: #1a202c; color: white; }}
                      .container {{ max-width: 1200px; margin: 0 auto; padding: 20px; }}
                      .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 30px; border-radius: 12px; text-align: center; }}
                      .metrics-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin: 30px 0; }}
                      .metric-card {{ background: #2d3748; padding: 25px; border-radius: 12px; border-left: 4px solid #4299e1; }}
                      .metric-title {{ font-size: 1.2em; font-weight: bold; margin-bottom: 15px; color: #63b3ed; }}
                      .metric-value {{ font-size: 2em; font-weight: bold; color: #68d391; }}
                      .metric-label {{ color: #a0aec0; font-size: 0.9em; }}
                      .status-good {{ color: #68d391; }}
                      .status-warning {{ color: #fbd38d; }}
                      .status-error {{ color: #fc8181; }}
                  </style>
              </head>
              <body>
                  <div class="container">
                      <div class="header">
                          <h1>üöÄ ArbitrageX Supreme</h1>
                          <p>Performance Testing Report - CI/CD Pipeline</p>
                          <p>Ingenio Pichichi S.A.</p>
                          <p>üìÖ {datetime.now().strftime("%Y-%m-%d %H:%M:%S UTC")}</p>
                      </div>
                      
                      <div class="metrics-grid">
              '''
              
              for test_type, data in results.items():
                  if not data:
                      continue
                  
                  metrics = data.get('metrics', {})
                  
                  # Extraer m√©tricas principales
                  http_reqs = metrics.get('http_reqs', {}).get('count', 0)
                  error_rate = metrics.get('http_req_failed', {}).get('rate', 0) * 100
                  avg_duration = metrics.get('http_req_duration', {}).get('avg', 0)
                  p95_duration = metrics.get('http_req_duration', {}).get('p95', 0)
                  
                  # Determinar estado
                  status_class = 'status-good'
                  if error_rate > 5:
                      status_class = 'status-error'
                  elif error_rate > 1 or p95_duration > 2000:
                      status_class = 'status-warning'
                  
                  html += f'''
                          <div class="metric-card">
                              <div class="metric-title">üß™ {test_type.title()} Tests</div>
                              <div class="metric-value {status_class}">{http_reqs}</div>
                              <div class="metric-label">Total Requests</div>
                              <hr style="margin: 15px 0; border-color: #4a5568;">
                              <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 10px;">
                                  <div>
                                      <div class="metric-label">Error Rate</div>
                                      <div style="font-weight: bold; color: {'#fc8181' if error_rate > 5 else '#68d391'};">{error_rate:.1f}%</div>
                                  </div>
                                  <div>
                                      <div class="metric-label">P95 Duration</div>
                                      <div style="font-weight: bold;">{p95_duration:.0f}ms</div>
                                  </div>
                              </div>
                          </div>
                  '''
              
              html += '''
                      </div>
                      
                      <div style="text-align: center; margin-top: 40px; color: #a0aec0;">
                          <p>üè≠ Ingenio Pichichi S.A. - ArbitrageX Supreme Performance Testing</p>
                          <p>Generated automatically by CI/CD Pipeline</p>
                      </div>
                  </div>
              </body>
              </html>
              '''
              
              return html
          
          # Generar reporte
          results = load_test_results()
          if results:
              html_report = generate_html_report(results)
              
              with open('performance/reports/consolidated_report.html', 'w') as f:
                  f.write(html_report)
              
              print("‚úÖ Reporte HTML generado exitosamente")
              
              # Imprimir resumen en consola
              print("\nüìä RESUMEN DE RESULTADOS:")
              print("=" * 50)
              
              for test_type, data in results.items():
                  if data:
                      metrics = data.get('metrics', {})
                      http_reqs = metrics.get('http_reqs', {}).get('count', 0)
                      error_rate = metrics.get('http_req_failed', {}).get('rate', 0) * 100
                      p95_duration = metrics.get('http_req_duration', {}).get('p95', 0)
                      
                      print(f"{test_type.upper():<12} | Requests: {http_reqs:<8} | Errors: {error_rate:<5.1f}% | P95: {p95_duration:<8.0f}ms")
              
              print("=" * 50)
          else:
              print("‚ùå No se encontraron resultados de pruebas")
              sys.exit(1)
          EOF
          
          # Ejecutar generador de reportes
          python3 performance/reports/generate_report.py

      - name: 'Upload Performance Report'
        uses: actions/upload-artifact@v4
        with:
          name: performance-report
          path: performance/reports/
          retention-days: ${{ env.RESULTS_RETENTION_DAYS }}

  notify-results:
    name: 'Notify Results'
    runs-on: ubuntu-latest
    needs: [setup-and-validate, smoke-tests, load-tests, websocket-tests, blockchain-tests, generate-report]
    if: always()
    
    steps:
      - name: 'Determine Overall Status'
        id: status
        run: |
          # Determinar estado general basado en los trabajos ejecutados
          if [[ "${{ needs.smoke-tests.result }}" == "failure" ]]; then
            echo "status=critical" >> $GITHUB_OUTPUT
            echo "message=Smoke tests failed - Critical issue detected" >> $GITHUB_OUTPUT
          elif [[ "${{ needs.load-tests.result }}" == "failure" || "${{ needs.websocket-tests.result }}" == "failure" || "${{ needs.blockchain-tests.result }}" == "failure" ]]; then
            echo "status=warning" >> $GITHUB_OUTPUT
            echo "message=Some performance tests failed - Review required" >> $GITHUB_OUTPUT
          else
            echo "status=success" >> $GITHUB_OUTPUT
            echo "message=All performance tests completed successfully" >> $GITHUB_OUTPUT
          fi

      - name: 'Notify Slack'
        if: env.SLACK_WEBHOOK != ''
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
        run: |
          color="good"
          emoji="‚úÖ"
          
          if [[ "${{ steps.status.outputs.status }}" == "critical" ]]; then
            color="danger"
            emoji="üö®"
          elif [[ "${{ steps.status.outputs.status }}" == "warning" ]]; then
            color="warning"
            emoji="‚ö†Ô∏è"
          fi
          
          curl -X POST -H 'Content-type: application/json' \
            --data "{
              \"attachments\": [{
                \"color\": \"$color\",
                \"title\": \"$emoji ArbitrageX Supreme - Performance Testing\",
                \"fields\": [{
                  \"title\": \"Environment\",
                  \"value\": \"${{ needs.setup-and-validate.outputs.environment }}\",
                  \"short\": true
                }, {
                  \"title\": \"Branch\",
                  \"value\": \"${{ github.ref_name }}\",
                  \"short\": true
                }, {
                  \"title\": \"Status\",
                  \"value\": \"${{ steps.status.outputs.status }}\",
                  \"short\": true
                }, {
                  \"title\": \"Trigger\",
                  \"value\": \"${{ github.event_name }}\",
                  \"short\": true
                }, {
                  \"title\": \"Message\",
                  \"value\": \"${{ steps.status.outputs.message }}\",
                  \"short\": false
                }, {
                  \"title\": \"Workflow\",
                  \"value\": \"<https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Details>\",
                  \"short\": false
                }],
                \"footer\": \"Ingenio Pichichi S.A.\",
                \"ts\": $(date +%s)
              }]
            }" "$SLACK_WEBHOOK" || echo "Failed to send Slack notification"

      - name: 'Comment on PR'
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const status = '${{ steps.status.outputs.status }}';
            const message = '${{ steps.status.outputs.message }}';
            
            let emoji = '‚úÖ';
            let statusText = 'SUCCESS';
            
            if (status === 'critical') {
              emoji = 'üö®';
              statusText = 'CRITICAL';
            } else if (status === 'warning') {
              emoji = '‚ö†Ô∏è';
              statusText = 'WARNING';
            }
            
            const body = `
            ## ${emoji} Performance Testing Results - ${statusText}
            
            **Environment:** \`${{ needs.setup-and-validate.outputs.environment }}\`
            **Test Type:** \`${{ needs.setup-and-validate.outputs.test_type }}\`
            
            ### Status Summary
            ${message}
            
            ### Test Results
            - **Smoke Tests:** ${{ needs.smoke-tests.result }}
            - **Load Tests:** ${{ needs.load-tests.result || 'skipped' }}
            - **WebSocket Tests:** ${{ needs.websocket-tests.result || 'skipped' }}
            - **Blockchain Tests:** ${{ needs.blockchain-tests.result || 'skipped' }}
            
            üìä [View Detailed Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
            
            ---
            *Generated by ArbitrageX Supreme CI/CD Pipeline - Ingenio Pichichi S.A.*
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });